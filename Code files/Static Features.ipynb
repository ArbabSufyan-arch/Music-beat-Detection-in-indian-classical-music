{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-WY0oFcNDjd"
   },
   "outputs": [],
   "source": [
    "!pip install spafe\n",
    "!pip install gammatone\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JLCsfEz13vp"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "import numpy as np\n",
    "from spafe.features.gfcc import gfcc\n",
    "from gammatone.gtgram import gtgram\n",
    "from scipy.fftpack import dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fi4mhurJ2e4f"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BV3k8wjB2hNS",
    "outputId": "704d6ba5-4c1b-4571-e811-79beace0465f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSRAmsnt2iXE"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/content/drive/MyDrive/audiov/\"\n",
    "JSON_PATH = \"/content/drive/MyDrive/datav/gmccx1v3.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 120 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0D5SPMXFubwU"
   },
   "outputs": [],
   "source": [
    "def compute_gammatone_spectrogram(y, sr, n_fft, hop_length, n_gammatone,f_min):\n",
    "\n",
    "    return gtgram(y, sr, n_fft/sr, hop_length/sr, n_gammatone,f_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfDZwbsoubmW"
   },
   "outputs": [],
   "source": [
    "def mel_scale_gammatone(gt_spectrogram, sr, n_mel):\n",
    "    mel_filterbank = librosa.filters.mel(sr=sr, n_fft=gt_spectrogram.shape[0]*2-1, n_mels=n_mel)\n",
    "    mel_spectrogram = np.dot(mel_filterbank, gt_spectrogram)\n",
    "    return mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NmHlskuulH1"
   },
   "outputs": [],
   "source": [
    "def compute_gmcc(y, sr, n_fft, hop_length, n_gammatone, n_mel, n_ceps):\n",
    "    # Compute gammatone spectrogram\n",
    "    f_min = 20\n",
    "    gt_spectrogram = compute_gammatone_spectrogram(y, sr, n_fft, hop_length, n_gammatone,f_min)\n",
    "\n",
    "    # Apply Mel filterbank\n",
    "    mel_spectrogram = mel_scale_gammatone(gt_spectrogram, sr, n_mel)\n",
    "\n",
    "    # Log transform\n",
    "    log_mel_spectrogram = np.log(mel_spectrogram + 1e-10)\n",
    "\n",
    "    # Compute DCT\n",
    "    gmcc = dct(log_mel_spectrogram, type=2, axis=0, norm='ortho')[1:(n_ceps + 1)]\n",
    "\n",
    "    return gmcc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RLi6xWQ2kXi"
   },
   "outputs": [],
   "source": [
    "# for amplitude envelope\n",
    "def amplitude_envelope(signal, frame_size, hop_length):\n",
    "    \"\"\"Calculate the amplitude envelope of a signal with a given frame size nad hop length.\"\"\"\n",
    "    amplitude_envelope = []\n",
    "\n",
    "    # calculate amplitude envelope for each frame\n",
    "    for i in range(0, len(signal), hop_length):\n",
    "        amplitude_envelope_current_frame = max(signal[i:i+frame_size])\n",
    "        amplitude_envelope.append(amplitude_envelope_current_frame)\n",
    "\n",
    "    return np.array(amplitude_envelope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8XgA099f24oN"
   },
   "outputs": [],
   "source": [
    "# band energy ratio\n",
    "def calculate_split_frequency_bin(split_frequency, sample_rate, num_frequency_bins):\n",
    "    \"\"\"Infer the frequency bin associated to a given split frequency.\"\"\"\n",
    "\n",
    "    frequency_range = sample_rate / 2\n",
    "    frequency_delta_per_bin = frequency_range / num_frequency_bins\n",
    "    split_frequency_bin = math.floor(split_frequency / frequency_delta_per_bin)\n",
    "    return int(split_frequency_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCnI9L1025hl"
   },
   "outputs": [],
   "source": [
    "split_frequency_bin = calculate_split_frequency_bin(2000, 22050, 1025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5HpopcL3B9Z"
   },
   "outputs": [],
   "source": [
    "def band_energy_ratio(spectrogram, split_frequency, sample_rate):\n",
    "    \"\"\"Calculate band energy ratio with a given split frequency.\"\"\"\n",
    "\n",
    "    split_frequency_bin = calculate_split_frequency_bin(split_frequency, sample_rate, len(spectrogram[0]))\n",
    "    band_energy_ratio = []\n",
    "\n",
    "    # calculate power spectrogram\n",
    "    power_spectrogram = np.abs(spectrogram) ** 2\n",
    "    power_spectrogram = power_spectrogram.T\n",
    "\n",
    "    # calculate BER value for each frame\n",
    "    for frame in power_spectrogram:\n",
    "        sum_power_low_frequencies = frame[:split_frequency_bin].sum()\n",
    "        sum_power_high_frequencies = frame[split_frequency_bin:].sum()\n",
    "        band_energy_ratio_current_frame = sum_power_low_frequencies / sum_power_high_frequencies\n",
    "        band_energy_ratio.append(band_energy_ratio_current_frame)\n",
    "\n",
    "    return np.array(band_energy_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfCYvXul3B6d"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_feature(dataset_path, json_path, num_segments=4 ):\n",
    "    # Dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"tal\": [],\n",
    "        \"ae\": [],\n",
    "        \"rmse\": [],\n",
    "        \"zcr\" : [],\n",
    "        \"ber\" : [],\n",
    "        \"sc\" : [],\n",
    "        \"sb\" : [],\n",
    "        \"sf\" : [],\n",
    "        \"mel\":[],\n",
    "        \"logm\":[],\n",
    "        \"mfcc\": [],\n",
    "        \"stft\":[],\n",
    "        \"gfcc\": [],\n",
    "        \"gmcc\":[]\n",
    "    }\n",
    "\n",
    "    hop_length = 512\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # Loop through all genre sub-folders\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        # Ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "            # Save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            s1 =  dirpath.split(\"/\")[-1].rstrip(\"\\\\\")  # Remove trailing backslashes\n",
    "\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "            data[\"tal\"].append(s1)\n",
    "            # Process all audio files in genre sub-dir\n",
    "            for f in filenames:\n",
    "                # Load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "\n",
    "                    #Extract amplitude envelope for the entire audio file\n",
    "                    ae_scale = amplitude_envelope(signal[start:finish], 1024 , 512)\n",
    "                    ae_scale = ae_scale.T\n",
    "                    store ae feature\n",
    "                    if len(ae_scale) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"ae\"].append(ae_scale.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "\n",
    "                    #Extarct RootMeanSqaureEnergy for audiofile\n",
    "                    rms_scale = librosa.feature.rms(y = signal[start:finish], frame_length=1024, hop_length=512)[0]\n",
    "                    rms_scale = rms_scale.T\n",
    "                    #store zcr feature\n",
    "                    if len(rms_scale) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"rmse\"].append(rms_scale.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "\n",
    "                    #Extarct zero crossing rate  for audiofile\n",
    "                    if len(signal[start:finish]) > 0:\n",
    "                    zcr_scale = librosa.feature.zero_crossing_rate(y=signal[start:finish], frame_length=1024, hop_length=512)[0]\n",
    "                    zcr_scale = zcr_scale.T\n",
    "                    #store zcr feature\n",
    "                    if len(zcr_scale) == num_mfcc_vectors_per_segment:\n",
    "                       data[\"zcr\"].append(zcr_scale.tolist())\n",
    "                       data[\"labels\"].append(i-1)\n",
    "\n",
    "                    #extract short time fourier transform spectrogram\n",
    "                    stft = librosa.stft(y=signal[start:finish], n_fft=2048, hop_length=512)\n",
    "                    # # S_db = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "                    # # S_db = S_db.T\n",
    "                    scale1 = np.abs(stft) ** 2\n",
    "                    scale1 = scale1.T\n",
    "                    # # store spectrogram\n",
    "                    # # if len(S_db) == num_mfcc_vectors_per_segment:\n",
    "                    if len(scale1) == num_mfcc_vectors_per_segment:\n",
    "                    #     #data[\"stft\"].append(S_db.tolist())\n",
    "                         data[\"stft\"].append(scale1.tolist())\n",
    "                         data[\"labels\"].append(i-1)\n",
    "\n",
    "                    #extract band energy ratio for audio file\n",
    "                    ber_scale = band_energy_ratio(stft, 2000, SAMPLE_RATE)\n",
    "                    ber_scale = ber_scale.T\n",
    "                    #store band feature\n",
    "                    if len(ber_scale) == num_mfcc_vectors_per_segment:\n",
    "                         data[\"ber\"].append(ber_scale.tolist())\n",
    "                         data[\"labels\"].append(i-1)\n",
    "\n",
    "                    #Extarct  spectral centriod for audio file\n",
    "                    sc_scale = librosa.feature.spectral_centroid(y=signal[start:finish], sr=SAMPLE_RATE, n_fft=1024, hop_length=512)[0]\n",
    "                    sc_scale = sc_scale.T\n",
    "                    #store sc\n",
    "                    if len(sc_scale) == num_mfcc_vectors_per_segment:\n",
    "                            data[\"sc\"].append(sc_scale.tolist())\n",
    "                            data[\"labels\"].append(i-1)\n",
    "\n",
    "                    #extract spectral Bandwith for audio file\n",
    "                    ban_scale = librosa.feature.spectral_bandwidth(y=signal[start:finish], sr=SAMPLE_RATE, n_fft=1024, hop_length=512)[0]\n",
    "                    ban_scale = ban_scale.T\n",
    "                    #store spectralbandwidth\n",
    "                    if len(ban_scale) == num_mfcc_vectors_per_segment:\n",
    "                             data[\"sb\"].append(ban_scale.tolist())\n",
    "                             data[\"labels\"].append(i-1)\n",
    "\n",
    "                    #extract spectral flux of auudio file\n",
    "                    spectral_flux = librosa.onset.onset_strength(y=signal[start:finish], sr=SAMPLE_RATE)\n",
    "                    spectral_flux = spectral_flux.T\n",
    "                    # #store band feature\n",
    "                    if len(spectral_flux) == num_mfcc_vectors_per_segment:\n",
    "                             data[\"sf\"].append(spectral_flux.tolist())\n",
    "                             data[\"labels\"].append(i-1)\n",
    "\n",
    "                    ##Extarct mel-spectogram  for audiofile\n",
    "                    mel_spectrogram = librosa.feature.melspectrogram(y=signal[start:finish], sr=SAMPLE_RATE, n_fft=2048, hop_length=512, n_mels=128)\n",
    "                    mel_spectrogram2 = mel_spectrogram.T\n",
    "\n",
    "                    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
    "                    log_mel_spectrogram = log_mel_spectrogram.T\n",
    "\n",
    "                    # store only mel spectogram  feature with expected number of vectors\n",
    "                    if len(log_mel_spectrogram) == num_mfcc_vectors_per_segment:\n",
    "                         data[\"mel\"].append(mel_spectrogram2.tolist())\n",
    "                         data[\"logm\"].append(log_mel_spectrogram.tolist())\n",
    "                         data[\"labels\"].append(i-1)\n",
    "\n",
    "                    # Extract mfcc for the entire audio file\n",
    "                    mfcc = librosa.feature.mfcc(y = signal[start:finish], sr = sample_rate, n_mfcc=40 , n_fft=2048, hop_length=512)\n",
    "                    mfcc = mfcc.T  # Transpose for shape compatibility\n",
    "                    # # store only mfcc feature with expected number of vectors\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "\n",
    "                    # Extract gfcc for the entire audio file\n",
    "                    gfcc_features2 = gfcc(signal[start:finish], fs=SAMPLE_RATE,\n",
    "                    num_ceps=40,  # Number of cepstral coefficients (default: 13)\n",
    "                    nfilts=128,     # Number of filters in the filterbank (default: 40)\n",
    "                    nfft=2048,      # Number of FFT points (default: 512)\n",
    "                    )\n",
    "                    gfcc_features = gfcc_features2.T  # Transpose for shape compatibility\n",
    "                    gfcc_features.shape[1] == num_mfcc_vectors_per_segment:\n",
    "                    data[\"gfcc\"].append(gfcc_features.tolist())\n",
    "                    data[\"labels\"].append(i-1)\n",
    "\n",
    "                    # # Extract gfcc for the entire audio file\n",
    "                    N_FFT = 2048\n",
    "                    HOP_LENGTH = 512\n",
    "                    N_GAMMATONE = 64\n",
    "                    N_MEL = 128\n",
    "                    N_CEPS = 13\n",
    "                    gmcc_features = compute_gmcc(signal[start:finish], SAMPLE_RATE, N_FFT, HOP_LENGTH, N_GAMMATONE, N_MEL, N_CEPS)\n",
    "                    if gmcc_features.shape[1] == num_mfcc_vectors_per_segment:\n",
    "                    data[\"gmcc\"].append(gmcc_features.tolist())\n",
    "                    data[\"labels\"].append(i - 1)\n",
    "\n",
    "\n",
    "                    print(\"{}, segments processed\".format(file_path, d+1))\n",
    "\n",
    "    # Save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "       json.dump(data, fp, indent=4)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_feature(DATASET_PATH, JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbVlWJ7rFyWB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
